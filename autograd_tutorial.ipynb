{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "autograd_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "88e628a95bfe43618176563861d65f80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c52425e2d6954fbba76679e9760cac91",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ccf5c63b8abd48e99d7cbebe26e5e6f1",
              "IPY_MODEL_f278942ac58449aeb9501b366581a9e3"
            ]
          }
        },
        "c52425e2d6954fbba76679e9760cac91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccf5c63b8abd48e99d7cbebe26e5e6f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b59ad69225b640edb4274babf9440ebc",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec898060c5c24492b04dd886ce50cbfb"
          }
        },
        "f278942ac58449aeb9501b366581a9e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8708c420af514c578d4eb387c6f7f0d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 152MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a4f06cbdcdd148fe8ae7626bff0f3d8c"
          }
        },
        "b59ad69225b640edb4274babf9440ebc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec898060c5c24492b04dd886ce50cbfb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8708c420af514c578d4eb387c6f7f0d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a4f06cbdcdd148fe8ae7626bff0f3d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ji-in/PyTorch/blob/main/autograd_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HiRn7b66Qxch"
      },
      "source": [
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tvtAzQxdQxcn"
      },
      "source": [
        "\n",
        "## A Gentle Introduction to ``torch.autograd``\n",
        "\n",
        "``torch.autograd``는 자동으로 미분을 해주는 Pytorch의 엔진이다. 이번 섹션에서, 어떻게 autograd가 신경망 훈련을 도와주는지 살펴보자.\n",
        "\n",
        "Background\n",
        "\n",
        "신경망은 두가지 단계를 거쳐서 훈련된다.\n",
        "\n",
        "1. Forward Propagation\n",
        "Forward prop에서, 신경망은 정확한 출력을 위해 최선의 추측을 한다. \n",
        "최선의 추측을 위해 입력 데이터를 각 함수에 통과시킨다.\n",
        "\n",
        "2. Backward Propagation\n",
        "Backprop에서, 신경망은 추측의 에러(loss)를 사용하여 파라미터를 조정한다.\n",
        "출력에서 시작해서 거꾸로 진행한다.\n",
        "함수의 파라미터에 대해서 에러의 미분을 모으고 (gradients), 경사 하강법(gradient descent)을 사용해 파라미터를 최적화한다.\n",
        "Backprop의 자세한 설명을 보고 싶다면, [3Blue1Brown](https://www.youtube.com/watch?v=tIeHLnjs5U8) 비디오를 확인해보자.\n",
        "\n",
        "\n",
        "단순한 훈련 과정을 통해 `autograd`에 대해 배워보자.  \n",
        "``torchvision``에서 pretrained resnet18 model을 불러온다.  \n",
        "우리는 random data tensor를 사용해서 channel=3, height=64, width=64를 가진 이미지를 하나 만들고, 그 이미지에 상응하는 ``label``은 random values로 초기화했다. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mkm10qFxQxcn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "88e628a95bfe43618176563861d65f80",
            "c52425e2d6954fbba76679e9760cac91",
            "ccf5c63b8abd48e99d7cbebe26e5e6f1",
            "f278942ac58449aeb9501b366581a9e3",
            "b59ad69225b640edb4274babf9440ebc",
            "ec898060c5c24492b04dd886ce50cbfb",
            "8708c420af514c578d4eb387c6f7f0d0",
            "a4f06cbdcdd148fe8ae7626bff0f3d8c"
          ]
        },
        "outputId": "3130b739-4590-4f4a-f79b-d866af650070"
      },
      "source": [
        "import torch, torchvision\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "data = torch.rand(1, 3, 64, 64)\n",
        "labels = torch.rand(1, 1000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88e628a95bfe43618176563861d65f80",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZ10YjVeQxco"
      },
      "source": [
        "예측을 하기 위해 입력 데이터를 모델의 각 레이어에 통과시킨다. **forward pass**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjljNudIQxco"
      },
      "source": [
        "prediction = model(data) # forward pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JluL2SQYQxco"
      },
      "source": [
        "모델의 에러(``loss``)를 계산하기 위해 모델의 예측값과 레이블을 사용한다.  \n",
        "다음 단계는 네트워크를 통과시켜 에러를 backpropagate 하는 것이다.  \n",
        "에러 tensor(``loss``)에서 ``.backward()``를 부르면 backward propagation이 시작된다.  \n",
        "Autograd는 파라미터의 ``.grad`` 속성에 존재하는 각 모델 파라미터의 기울기를 계산하고 저장한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuN3vc8TQxcp"
      },
      "source": [
        "loss = (prediction - labels).sum()\n",
        "loss.backward() # backward pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBpPocxpQxcp"
      },
      "source": [
        "Optimizer를 부른다.  \n",
        "이번 경우, optimizer=SGD, learning rate=0.01, momentum=0.9를 사용한다.\n",
        "모델의 모든 파라미터를 optimizer에 등록한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0BZZpnEQxcp"
      },
      "source": [
        "optim = torch.optim.SGD(model.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhH34Rk6Qxcq"
      },
      "source": [
        "마지막으로, ``.step()``를 불러 gradient descent를 초기화한다.  \n",
        "Optimizer는 ``.grad``에 저장된 gradient에 따라 각 파라미터를 조정한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HcbP16nQxcq"
      },
      "source": [
        "optim.step() #gradient descent"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjhM2vdSQxcq"
      },
      "source": [
        "신경망을 학습하기 위해 필요한 것은 전부 다 했다.  \n",
        "아래의 섹션은 구체적인 autograd의 동작에 관한 것이다.  \n",
        "건너 뛰어도 된다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQ5EEfSvQxcq"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xiq_7p02Qxcq"
      },
      "source": [
        "Differentiation in Autograd\n",
        "~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
        "\n",
        "``autograd``가 어떻게 gradients를 모으는지 확인해보자.  \n",
        "``require_grad=True``를 사용해 두 개의 tensor인 ``a``와 ``b``를 만든다.\n",
        "``require_grad=True``는 ``a``와 ``b``에 관련된 모든 연산을 추적하라고 ``autograd``에 신호를 보낸다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw516DXSQxcr"
      },
      "source": [
        "import torch\n",
        "\n",
        "a = torch.tensor([2., 3.], requires_grad=True)\n",
        "b = torch.tensor([6., 4.], requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SgOrBrr9Qxcr"
      },
      "source": [
        "``a``와 ``b``를 사용해 또다른 tensor ``Q``를 만든다.\n",
        "\n",
        "\\begin{align}Q = 3a^3 - b^2\\end{align}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1A1kQ3IrQxcr"
      },
      "source": [
        "Q = 3*a**3 - b**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IA_w1Y6VQxcs"
      },
      "source": [
        "``a``와 ``b``는 신경망의 파라미터, ``Q``는 에러라고 하자.    \n",
        "신경망을 훈련할 때, 에러를 파라미터로 미분한 **에러의 gradients**가 필요하다. 즉,  \n",
        "\n",
        "\\begin{align}\\frac{\\partial Q}{\\partial a} = 9a^2\\end{align}\n",
        "\n",
        "\\begin{align}\\frac{\\partial Q}{\\partial b} = -2b\\end{align}\n",
        "\n",
        "\n",
        "``Q``에서 ``.backward()``를 부르면, autograd는 gradients를 계산하고 ``.grad`` 속성을 가진 tensor에 gradients를 저장한다. ``gradient``가 vector이기 때문에 ``Q.backward()``에 ``gradient`` 를 명시적으로 전달해야한다.  \n",
        "``Q``를 자기 자신에 대해 미분한 ``gradient``는 ``Q``와 shpae이 같은 tensor이다. 즉, \n",
        "\n",
        "\\begin{align}\\frac{dQ}{dQ} = 1\\end{align}\n",
        "\n",
        "``Q.sum().backward()``와 같이 Q를 scalar로 만들어서 backward를 부를 수도 있다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58bnQHvvQxcs"
      },
      "source": [
        "external_grad = torch.tensor([1., 1.])\n",
        "Q.backward(gradient=external_grad)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfcqKDwCQxcs"
      },
      "source": [
        "Gradients는 ``a.grad``와 ``b.grad``에 저장된다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gko4yGzKQxcs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2d0675f-ce6d-4995-a3bc-ce18e03ec139"
      },
      "source": [
        "# gradient가 잘 구해졌는지 확인해보자.\n",
        "print(9*a**2 == a.grad)\n",
        "print(-2*b == b.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([True, True])\n",
            "tensor([True, True])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3GxJlM6Qxct"
      },
      "source": [
        "**추가적으로 읽을 것 - ``autograd``를 사용해서 벡터 연산하기**\n",
        "\n",
        "\n",
        "수학적으로, 벡터를 입력으로 받는 함수 $\\vec{y}=f(\\vec{x})$ 가 있다면, $\\vec{y}$ 를 $\\vec{x}$에 대해서 미분한 것은 Jacobian matrix $J$가 된다.:\n",
        "\n",
        "\\begin{align}J\n",
        "     =\n",
        "      \\left(\\begin{array}{cc}\n",
        "      \\frac{\\partial \\bf{y}}{\\partial x_{1}} &\n",
        "      ... &\n",
        "      \\frac{\\partial \\bf{y}}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\n",
        "     =\n",
        "     \\left(\\begin{array}{ccc}\n",
        "      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{1}}{\\partial x_{n}}\\\\\n",
        "      \\vdots & \\ddots & \\vdots\\\\\n",
        "      \\frac{\\partial y_{m}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\\end{align}\n",
        "\n",
        "일반적으로, ``torch.autograd``는 vector와 Jacobian의 곱을 계산하는 엔진이다. 즉, 어떤 벡터 $v=(v _{1}  v _{2} ... v _{m} ) ^{T}$에 대해 $J^{T}\\cdot \\vec{v}$를 계산한다.\n",
        "\n",
        "만약 $v$가 스칼라 함수 $l=g\\left(\\vec{y}\\right)$의 기울기인 경우, $v=\\left(\\begin{array}{ccc}\\frac{\\partial l}{\\partial y_{1}} & \\cdots & \\frac{\\partial l}{\\partial y_{m}}\\end{array}\\right)^{T}$ 이며,\n",
        "\n",
        "Chain rule에 의해, vector와 Jacobian 곱은 $\\vec{x}$에 대한 $l$의 미분이 된다.\n",
        "\n",
        "\\begin{align}J^{T}\\cdot \\vec{v}=\\left(\\begin{array}{ccc}\n",
        "      \\frac{\\partial y_{1}}{\\partial x_{1}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{1}}\\\\\n",
        "      \\vdots & \\ddots & \\vdots\\\\\n",
        "      \\frac{\\partial y_{1}}{\\partial x_{n}} & \\cdots & \\frac{\\partial y_{m}}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\\left(\\begin{array}{c}\n",
        "      \\frac{\\partial l}{\\partial y_{1}}\\\\\n",
        "      \\vdots\\\\\n",
        "      \\frac{\\partial l}{\\partial y_{m}}\n",
        "      \\end{array}\\right)=\\left(\\begin{array}{c}\n",
        "      \\frac{\\partial l}{\\partial x_{1}}\\\\\n",
        "      \\vdots\\\\\n",
        "      \\frac{\\partial l}{\\partial x_{n}}\n",
        "      \\end{array}\\right)\\end{align}\n",
        "\n",
        "  \n",
        "``external_grad``는 $\\vec{v}$를 나타낸다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltiuBPHJQxct"
      },
      "source": [
        "Computational Graph\n",
        "\n",
        "개념상으로, autograd는 텐서들과 모든 실행됐던 연산들을 directed acyclic graph (DAG)에 저장한다.\n",
        "DAG에서, 리프 노드는 input tensors이고 루트 노드는 output tensors이다.\n",
        "그래프의 루트에서부터 리프까지 탐색하면서, chain rule을 사용하여 자동적으로 gradients를 계산할 수 있다.\n",
        "\n",
        "Forward pass에서, autograd는 동시에 두가지 일을 한다.\n",
        "\n",
        "- 요청된 작업을 실행하여 결과 텐서를 계산한다.\n",
        "- DAG에서 연산의 gradient function을 유지한다.\n",
        "\n",
        "Backward pass는 DAG의 루트에서 `.backward()`가 불리면 시작된다. 그때 ``autograd``는\n",
        "\n",
        "- 각 `.grad_fun`에서 gradients를 계산한다.\n",
        "- gradients는 `.grad` 속성을 가진 텐서에 저장한다.\n",
        "- chain rule을 사용해서, 리프 텐서까지 전파된다.\n",
        "\n",
        "아래의 그림은 우리 예제를 가지고 DAG를 그린 것이다. 그래프에서, 화살표는 forward pass의 방향을 나타낸다. 노드들은 각 연산의 backward 함수를 나타낸다. 파랑색으로 나타낸 리프 노드는 우리의 리프 텐서인 `a`와 `b`를 나타낸다.\n",
        "\n",
        ".. figure:: /_static/img/dag_autograd.png\n",
        "\n",
        "<div class=\"alert alert-info\"><h4>Note</h4><p>**DAGs are dynamic in PyTorch**\n",
        "  주목해야 할 점은 그래프가 처음부터 다시 생성된다는 것이다.\n",
        "각각의 ``.backward()``함수가 불리면, autograd는 새 그래프를 만들기 시작한다. 이것은 모델에서 control flow statements를 사용할 수 있도록 하는 것이다. 필요하다면 그래프의 모양, 크기, 연산을 매 iteration마다 바꿀 수 있다.</p></div>\n",
        "\n",
        "\n",
        "Exclusion from the DAG\n",
        "\n",
        "\n",
        "``torch.grad``는 ``requires_grad``가 ``True``로 설정된 모든 텐서의 연산을 추적한다. ``requires_grad``가 ``False``로 설정된 텐서들은 gradient computation DAG에서 배제된다.\n",
        "\n",
        "한 개의 입력 텐서만 ``require_grad=True``일지라도, 연산의 결과 텐서는 gradients를 필요로 한다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4AOFAQ-Qxcu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de1661ce-ad16-46b4-98ad-ae3f2a870d17"
      },
      "source": [
        "x = torch.rand(5, 5)\n",
        "y = torch.rand(5, 5)\n",
        "z = torch.rand((5, 5), requires_grad=True)\n",
        "\n",
        "a = x + y\n",
        "print(f\"Does `a` require gradients? : {a.requires_grad}\")\n",
        "b = x + z\n",
        "print(f\"Does `b` require gradients?: {b.requires_grad}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Does `a` require gradients? : False\n",
            "Does `b` require gradients?: True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCyie-ClQxcu"
      },
      "source": [
        "신경망에서, gradients를 계산하지 않는 파라미터를 **frozen parameters**라고 한다.  \n",
        "어떤 파라미터들의 gradients가 필요없는 것을 미리 안다면, \"freeze\"는 모델에서 유용하게 쓰인다. (autograd 계산을 줄여 모델의 성능을 높일 수 있다.)\n",
        "\n",
        "DAG에서 제외되는 것이 중요한 것을 알려주는 또다른 경우는 [pretrained network를 finetuning 하는 경우이다.](https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html)\n",
        "\n",
        "Finetuning에서, 모델의 대부분을 고정하고 새로운 레이블을 예측하기 위해 classifier 레이어만 수정한다.  \n",
        "이것을 설명하기 위해 작은 예제를 살펴보자.  \n",
        "위에서, 우리는 pretrained resnet18 모델을 부르고, 모든 파라미터들을 고정했다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyJQjl1SQxcv"
      },
      "source": [
        "from torch import nn, optim\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# Freeze all the parameters in the network\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNYmoRT7Qxcv"
      },
      "source": [
        "10개의 레이블을 가진 새로운 데이터 셋에서 모델을 finetune을 한다고 하자.  \n",
        "Resnet에서, classifier는 마지막 레이어인 ``model.fc``이다.  \n",
        "우리는 간단히 이 레이어를 우리의 classifier로 사용될 새로운 선형 레이어로 교체할 수 있다. (기본적으로 unfrozen 되었다.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwyQBVi_Qxcv"
      },
      "source": [
        "model.fc = nn.Linear(512, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WI7C286LQxcv"
      },
      "source": [
        "``model.fc``의 파라미터를 제외한 모델의 모든 파라미터는 frozen되었다.  \n",
        "Gradients를 계산할 파라미터는 ``model.fc``의 weights와 bias이다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcPCeFMNQxcw"
      },
      "source": [
        "# Optimize only the classifier\n",
        "optimizer = optim.SGD(model.fc.parameters(), lr=1e-2, momentum=0.9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFAfNE2NQxcw"
      },
      "source": [
        "모든 파라미터를 optimizer에 등록했지만, gradients를 계산하고 경사 하강법으로 업데이트 되는 파라미터들은 classifier의 weights와 bias이다.\n",
        "\n",
        "동일한 제외 기능은 [torch.no_grad()](https://pytorch.org/docs/stable/generated/torch.no_grad.html)에서 이용 가능하다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "em7QfSSdQxcw"
      },
      "source": [
        "--------------\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CE3OviPeQxcw"
      },
      "source": [
        "더 읽을만한 것들:\n",
        "\n",
        "\n",
        "-  [In-place operations & Multithreaded Autograd](https://pytorch.org/docs/stable/notes/autograd.html)\n",
        "-  [Example implementation of reverse-mode autodiff](https://colab.research.google.com/drive/1VpeE6UvEPRz9HmsHh1KS0XxXjYu533EC)\n",
        "\n"
      ]
    }
  ]
}